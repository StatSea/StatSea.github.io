---
layout: single
title: "[DL] 딥러닝 03wk2"
categories: [DL]
tags: [DL]
mathjax: true
---
딥러닝 03wk2 이해하기

---
# 기본 세팅

```python
import torch
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
plt.rcParams['figure.figsize'] = (4.5, 3.0)
```
---
# 3. 로지스틱 최초적합
## A. 로지스틱 모형

- 우리가 예측하려는 것
  - 회귀모형 : 정규분포의 평균
    - 예측값 : $$\hat{w}_0 + \hat{w}_1x_i$$
  - 로지스틱 : 베르누이의 평균
    - 예측값 : $$\frac{\exp(\hat{w}_0+\hat{w}_1x_i)}{1+\exp(\hat{w}_0+\hat{w}_1x_i)}$$
---  

## B. 데이터
```python
torch.manual_seed(43052)
x = torch.linspace(-1,1,2000).reshape(2000,1)
w0,w1 = -1, 5
prob = torch.exp(w0+w1*x) / (1+torch.exp(w0+w1*x))
y = torch.bernoulli(prob)
```
```python
plt.plot(x,y,'.',alpha=0.03)
plt.plot(x[0],y[0],'.',label=r"$(x_i,y_i)$",color="C0")
plt.plot(x,prob,'--r',label=r"prob (true, unknown) = $\frac{exp(-1+5x)}{1+exp(-1+5x)}$")
plt.legend()
```
![image](https://github.com/user-attachments/assets/a82926ad-97f8-4ee4-8783-64dc0072dc38)
---

## C.Step1 : net 설계 (모델링)
`-` 최초의 곡선 그리기
   - 최초의직선: $$\hat{y}_i= \hat{w}_0+\hat{w}_1x_i$$ 에서 아무 $$\hat{w}_0$$, $$\hat{w}_1$$ 을 설정하면 된다.
  - 최초의곡선: $$\hat{y}_i= \frac{\exp(\hat{w}_0+\hat{w}_1x_i)}{1+\exp(\hat{w}_0+\hat{w}_1x_i)}=\frac{1}{1+\exp(-\hat{w}_0-\hat{w}_1x_i)}$$ 에서 아무 $$\hat{w}_0$$, $$\hat{w}_1$$ 을 설정하면 된다.

- 일단은 초기 설정값을 $$\hat{w}_0 = -0.8$, $\hat{w}_1 = -0.3$$ 으로 하자. (실제값은 $$w_0=-1$$, $$w_1=5$$ 이다)

### 방법 1. l1 , sigmoid
```python
# w0hat + w1hat*x
l1 = torch.nn.Linear(1,1)
l1.weight.data = torch.tensor([[-0.3]])
l1.bias.data = torch.tensor([-0.8])

- sigmoid 함수 생성
```python
def sigmoid(x):
    return torch.exp(x)/(1+torch.exp(x))
```
- 시각화 하기
```python
plt.plot(x,y,'.',alpha=0.03)
plt.plot(x[0],y[0],'o',label=r"$(x_i,y_i)$",color="C0")
plt.plot(x,prob,'--r',label=r"prob (true, unknown) = $\frac{exp(-1+5x)}{1+exp(-1+5x)}$")
plt.plot(x,sigmoid(l1(x)).data,'--b', label=r"prob (estimated) = $(x_i,\hat{y}_i)$ -- first curve")
plt.legend()
```
![image](https://github.com/user-attachments/assets/88605ca5-cef5-438b-88d7-f7cbdd348b32)

### 방법 2. l1, a1
```python
l1 = torch.nn.Linear(1,1)
l1.weight.data = torch.tensor([[-0.3]])
l1.bias.data = torch.tensor([-0.8])
a1 = torch.nn.Sigmoid()

# 시각화
plt.plot(x,y,'.',alpha=0.03)
plt.plot(x[0],y[0],'o',label=r"$(x_i,y_i)$",color="C0")
plt.plot(x,prob,'--r',label=r"prob (true, unknown) = $\frac{exp(-1+5x)}{1+exp(-1+5x)}$")
plt.plot(x,a1(l1(x)).data,'--b', label=r"prob (estimated) = $(x_i,\hat{y}_i)$ -- first curve with $(a_1 \circ l_1)(x)$")
plt.legend()
```
- 방법 1과 같은 답이 나온다.
![image](https://github.com/user-attachments/assets/2098d86a-6c38-4243-ba26-0bff0e74c2c8)

### 방법 3. l1 , a1만들고 -> net
- $${\bf x} \overset{l_1}{\to} {\bf u} \overset{a_1}{\to} {\bf v} = \hat{\bf y}$$ 로 된 구조
- $$(a_1\circ l_1)({\bf x}) := net({\bf x})$$ 로 바꾸기

```python
l1 = torch.nn.Linear(1,1)
l1.weight.data = torch.tensor([[-0.3]])
l1.bias.data = torch.tensor([-0.8])
a1 = torch.nn.Sigmoid()
# l1 먼저, 그 다음 a1
net = torch.nn.Sequential(l1,a1)
```
- 동일한 결과가 나온다.
- net의 구조는 어떻게 되어 있을까?
```python
l1 is net[0]
a1 is net[1]
```
- 전부 true로 출력된다.

### 방법 4. net을 바로 만들기

```python
net = torch.nn.Sequential(
    torch.nn.Linear(1,1),
    torch.nn.Sigmoid()
)
net[0].weight.data = torch.tensor([[-0.3]])
net[0].bias.data = torch.tensor([-0.8])
yhat = net(x)
```

## D. Step 1~4
```python
net = torch.nn.Sequential(
    torch.nn.Linear(in_features=1, out_features=1),
    torch.nn.Sigmoid()
)
l1, a1 = net
l1.weight.data = torch.tensor([[-0.3]])
l1.bias.data = torch.tensor([-0.8])
optimizr = torch.optim.SGD(net.parameters(),lr=0.25)
#---#
for epoc in range(100):
    ## 1
    yhat = net(x)
    ## 2
    loss = torch.mean((y-yhat)**2)
    ## 3
    loss.backward()
    ## 4
    optimizr.step()
    optimizr.zero_grad()
```

|변수|의미|직접 사용|
|----|----|----|
|l1|	Linear 계층 |가중치 설정 위해 필요|	
|a1|	Sigmoid 계층|자동 호출됨|

### 시각화 
```python
plt.plot(x,y,'.',alpha=0.05)
plt.plot(x,prob,'--r')
plt.plot(x,yhat.data,'--b')
plt.title('after 100 epochs')
```

- 빨간색 선은 이상적인 선
- 우리가 맞춰나가고 있는건 파란색 선
![image](https://github.com/user-attachments/assets/97d98bd5-1d3f-44d0-86cc-a42bd09d47d4)

- 에폭을 늘리면 될 것 같아 보임

```python
for epoc in range(4900):
    ## 1
    yhat = net(x)
    ## 2
    loss = torch.mean((y-yhat)**2)
    ## 3
    loss.backward()
    ## 4
    optimizr.step()
    optimizr.zero_grad()
```
```python
plt.plot(x,y,'.',alpha=0.05)
plt.plot(x,prob,'--r')
plt.plot(x,yhat.data,'--b')
plt.title('after 5000 epochs')
```
![image](https://github.com/user-attachments/assets/e8f6375a-6721-4967-9e5f-98c4f1434985)

