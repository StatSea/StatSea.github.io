---
layout: single
title: "[ML] 기계학습 Chap 6 "
categories: [ML]
tags: [ML]
mathjax: true
---
기계학습 Chap 6 정리

---

# improving linear models

`-` Prediciton accuarcy

- 만약 p << n 이면, 선형모형 하에서 최소제곱추정량은 좋은 성능을 보인다.
- 하지만 p >> n 이면, 추정에 변동성이 커진다. 이는 보통 과적합이 발생하여 예측성능을 저하시킨다.

`-` model interpretability

- 반응변수에 별 다른 영향력이 없는 예측변수는 모형의 복잡성만을 초래한다.
- 위와 같은 변수를 제거(계수를 0으로 만드는 것과 동일) 함으로써 모형의 해석을 보다 용이하게 할 수 있다.
- 변수가 고차원인 경우 해석만이 아니라 성능의 저하도 가져온다.
![image](https://github.com/user-attachments/assets/311cabf3-ea64-41df-a064-ceb3a1f19e3b)

# 최소제곱추정에 대한 대안 3가지

`-` subset selection

  - 전체 예측변수들 중 모형에 포함시킬 일부(부분 집합)를 식별하고자 함
  - 몇개를 날려버리고 중요한 몇개만 사용하기
  - 바닥을 훑는 것과 같음
  - 장점 : 잘됌
  - 단점 : 동원할 수 있는 변수의 개수가 데이터 사이즈에 의존됌, 어렵고 시간이 많이 듬

`-` Shrinkage 

  - p개의 예측변수를 모두 포함하여 자료를 적합하되, 추정된 계수들에는 0을 향한 축소가 일어남.
  - 이러한 축소는 추정량의 분산을 감소시킴
  - 회귀계수를 작은 값으로 쓰기 때문에 변동이 줄어들어 분산이 축소된다.
  - 앞에 곱하는 계수와 연결이 되는 변수를 없애지 않고 줄이기만 한다. 이로 인해 많은 변수들이 자연스럽게 날라간다.
  - 가장 주목받는 방법이다. 
    
`-` Dimension reduction

  - p개의 예측변수로 이루어진 공간을 M < p차원의 부분 공간으로 정사영한 후 모형 적합
  - 변수의 특성을 유지하는 새로운 변수들을 만든다.
  - 분산, 평균 등등 특성을 반드시 유지해야한다.
  - 10000개로 예측한 것과 3개로 예측한 결과를 똑같이 하는 것이다.
  - 예를 들면 pca가 있다. ( 주성분 분석 )
  - 단점 : 많은 변수들을 어떻게 추리느냐에 따른 문제, 예상외로 성능저하가 심함

# Best subset selection
- $$k$$개의 예측변수를 포함하는 모형  
  $$\binom{p}{k}$$개의 모형을 모두 적합하여 적절한 기준으로 가장 좋은 모형을 선택  
  $$(\mathcal{M}_k)$$.

- $$k = 0, 1, \dots, p$$에 대하여 위 과정을 반복하여  
  $$\mathcal{M}_0, \dots, \mathcal{M}_p$$ 생성.

- 교차타당검증, $$C_p$$, $$AIC$$, $$BIC$$, adjusted-$$R^2$$ 등을 이용하여  
  $$\mathcal{M}_0, \dots, \mathcal{M}_p$$ 중 가장 우수한 모형 선택.

- $$p$$가 커짐에 따라 계산량이 매우 많아지는 단점이 있음.
- 계산량 : $$2^p$$
![image](https://github.com/user-attachments/assets/5659e28a-8ea3-4767-aa93-2f5512c62516)

# Forward stepwise selection (전진선택)
- 예측변수가 없는 모형 $$\mathcal{M}_0$$에서 출발.

- $$k = 0, \dots, p - 1$$에 대하여 다음을 실행.

   - $$\mathcal{M}_k$$에서 하나의 변수가 추가된 $$p - k$$개의 모형을 고려.

   - 적절한 기준에서 가장 우수한 모형 선택 ($$\mathcal{M}_{k+1}$$).

- 교차타당검증, $$C_p$$, $$AIC$$, $$BIC$$, adjusted-$$R^2$$, 검증 데이터에서의 예측오차 등을 이용하여  
   $$\mathcal{M}_0, \dots, \mathcal{M}_p$$ 중 가장 우수한 모형 선택.

- $$1 + \sum_{k=0}^{p-1}(p - k) = 1 + \frac{p(p + 1)}{2}$$번의 모형 적합 필요.

- Step 2(b)와 Step 3의 기준은 다르게 설정이 되는 것도 가능함.
  - 하지만 다르게 설정하지 않는게 좋다.

- 계산량은 경감되나 best model을 선택할 수 있다는 보장은 없음.
![image](https://github.com/user-attachments/assets/6776925c-ecb8-4283-ae18-487abf899c37)

# Backward stepwise selection (후진선택)
- 예측변수가 모두 포함된 모형 $$\mathcal{M}_p$$에서 출발.

- $$k = p, p - 1, \dots, 1$$에 대하여 다음을 실행.

  - $$\mathcal{M}_k$$에서 하나의 변수만을 제외한 $$k$$개의 모형을 각각 고려.

  - $$RSS$$ 혹은 $$R^2$$의 관점에서 가장 우수한 모형 선택 ($$\mathcal{M}_{k-1}$$).

- 교차타당검증, $$C_p$$, $$AIC$$, $$BIC$$, adjusted-$$R^2$$,  
  검증 데이터에서의 예측오차 등을 이용하여  
  $$\mathcal{M}_0, \dots, \mathcal{M}_p$$ 중 가장 우수한 모형 선택.

- Forward와 비슷하나 진행방향이 반대.

- $$1 + \sum_{k=1}^{p} k = 1 + \frac{p(p + 1)}{2}$$번의 모형 적합 필요.

- 계산량은 경감되나 best model을 선택할 수 있다는 보장은 없음.
![image](https://github.com/user-attachments/assets/b48021a1-2edb-4cef-9b12-4d4577011211)

# Hybrid approaches
- forward + wackward , 모형의 복잡도가 순증가/순감소 하는 방식으로 찾는 단점을 보완

# 최적 모형 선택
- 최적모형 선택을 위해서는 test error에 대한 추정이 필요한데 여기에는 두 가지 접근법이 있을 수 있음
- 교차타당검증을 이용하여 직접적으로 test error를 추정
- training error에 과적합 등에 따른 편의를 고려한 보정을 가하는 방식으로 간접적으로 test error를 추정

# 평가 측도
- $$RSS$$, $$R^2$$ 등은 모형의 복잡도에 따라 단조적으로 변하는 척도이므로  
  최적모형 선택에 도움이 되지 않음.
  - $$R^2$$은 변수의 개수가 늘어나면 그냥 증가함
- Training error를 모형의 크기(복잡도 혹은 모수의 개수)에 대하여 보정한 척도들 활용.

- 다음과 같은 4가지 척도를 소개:  
  $$C_p$$, Akaike information criterion (AIC),  
  Bayesian information criterion (BIC), adjusted-$$R^2$$

- 피팅을 몇 번 안하고 예측오차를 알 수 있는 방법 : LOOCV

# Cp
- $$p$$개의 예측변수를 포함한 모형에서 test MSE에 대한 추정량으로 다음과 같은 통계량이 제안됨.

  $$
  C_p = \frac{1}{n} (RSS + 2p\hat{\sigma}^2)
  $$

  참고로  
  $$
  E[(y' - x^\top \hat{\beta})^2] - E[(y - x^\top \hat{\beta})^2] = 2p\hat{\sigma}^2
  $$  
  여기에서 $$y'$$은 평가데이터에서, $$y$$는 훈련데이터에서 나옴.  
  여기서 $$\hat{\sigma}^2$$은 오차항의 분산 추정치임.

- $$RSS$$는 모형이 복잡해지면 감소하고 $$2p\hat{\sigma}^2$$는 증가함.

- $$C_p$$ 값이 작을수록 우수한 모형으로 평가함.
![image](https://github.com/user-attachments/assets/48d38864-7967-4b51-88e3-8e2717ede469)
