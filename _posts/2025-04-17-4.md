---
layout: single
title: "[ML] 기계학습 Chap 5 "
categories: [ML]
tags: [ML]
mathjax: true
---
기계학습 Chap 5 정리

---
# Cross - Validation (교차검증)
- training error와 test error는 종종 매우 다른 양태를 보인다.
- test error에 대한 정확한 추정을 위해 모형 훈련 및 적합을 위한 자료와 평가를 위한 자료를 분리하는 것이 타당하다.
- 자료의 특성, 크기, 분석자의 여건 등에 따라 다른 방식이 적용될 수 있음.

- 새로운 데이터에서 얼마나 잘 예측이 되는지 평가를 하는 것이 중요하다
- validation = test = 새로운 데이터에서 적응을 잘 하는지 검사

# Validation set approach 
- 전체 자료를 랜덤하게 두 그룹으로 분할하여 각각 훈련/평가 자료로 사용한다.
- 정해진 기준은 없으나 보통 훈련 : 평가의 비율을 5:5 or 7:3 정도로 할당한다.
- test error 를 추정하기 위한 가장 간단한 방법이다.
- 평가 자료는 validation set, hold-out set 등으로 불린다.
- validation과 test는 같은 의미로 쓰일때도 있고 아닐때도 있지만 여기서는 같은 의미로 쓰기로 한다.

## Validation set approach 
- 랜덤하게 train 과 test 를 비율에 맞춰 분할한다.
- 따라서 train, test 경우의 수가 매우 많다.

### 단점
- 랜덤하게 자료를 분할하기 때문에 분할 결과에 따라 추정의 변동성이 클 수 있다. 자료의 크기가 작거나 이상/영향치가 포함되어 있는 경우에 더욱 그러하다.
- 원 자료의 크기보다 작은 집합의 훈련자료가 모형적합에 사용되기 때문에 test error가 과대 추정 될 수 있다. => 예측오차가 커진다
- 훈련 데이터를 쪼개서 훈련/ 평가로 나누고 실제 적합에서는 훈련 데이터 전체를 사용한다.

   1. 훈련, 평가 쪼개서 훈련 데이터로 예측
   2. 훈련, 평가 쪼개고 훈련 + 평가 데이터로 예측
      - 데이터가 아까워서 2번 방법을 선택하는데 이러면 과대 추정이 발생한다.

# test error의 추정
- 다양한 차수의 다항회귀 모형에 대한 test error 추정치
- 오른쪽 그림 : 자료의 분할을 10번 반복하여 추정된 test error들의 결과

![image](https://github.com/user-attachments/assets/00332144-d3c5-4373-9925-1ff36485a0be)

- 그래프들의 경향은 비슷한데 변동이 크다.
  - 이상치, 데이터 수 때문에 그런 것 같아 보인다.

# LOOCV 
- Validation set approach의 단점을 해소할 수 있는 방법
- 자료의 크기가 n이면 n-1의 훈련자료와 1개의 평가자료로 분할한다.
- test error 추정하는 법
![image](https://github.com/user-attachments/assets/0cd77c01-8905-4b07-9c89-588c078779d4)
  - i번째를 제외한 나머지로 예측한 것, 이 과정을 n번 반복한다.

- test MSE에 대한 LOOCV 추정치
  ![image](https://github.com/user-attachments/assets/ea096eda-f787-4754-a8aa-603d4c218323)

## 장단점

`-` 장점

- N-1 개의 자료를 모형 적합에 사용하기 때문에 정보량의 손해가 거의 없어 test error의 과대 추정에 대한 염려로부터 자유로움
- 자료의 분할에 따른 불확실성이 나타나지 않는다. ( 모든 자료가 똑같이 test set에 한번씩 포함돼서 )

`-` 단점

- 계산량이 너무 많아 자료의 크기가 매우 크거나 적합모형의 계산에 시간이 많이 소요되는 경우 적용에 제한이 따른다.

![image](https://github.com/user-attachments/assets/85c602b4-a19b-4e11-94bd-c5e9bc7695c2)

# LOOCV의 단순화
- 다항회귀모형의 경우 다음과 같은 단순화가 가능하다.

![image](https://github.com/user-attachments/assets/22e78d39-b29d-4b19-aeaf-189f394cbf9f)
  - 여기서 h 는 hat matrix의 i번째 대각원소이다.
  - 전체를 써서 한 번 피팅한 결과이다.
  - 1-h 값이 작아지면 전체 값이 커지고, 1-h 값은 0~1사이의 값이다.

- 위 식을 사용할 경우 한 번의 모형 적합을 통해 CV test error를 얻을 수 있다.
- 일반적으로 위와 같은 단순화가 항상 가능하지는 않지만 LOOCV의 장점을 유지하면서 계산량이 많다는 단점을 해소하기 위해 위와 비슷한 꼴의 단순화에 대한 연구가 이루어진다.

# k-Fold Cross Validation 2
- 데이터가 충분히 많지 않은 경우 데이터를 최대한 쓰기 위해 k-fold 2 를 사용한다.
- Validation set approach 대비 loocv의 장점은 어느정도 유지하면서 계산량을 경감하기 위한 시도이다.
- 전체 자료를 k개의 집합으로 분할한 후 그 중 하나의 집합(i번째)를 평가 자료로 설정한다.
- i번째 평가자료를 이용한 test error 추정치를 MSE라 하면 k-fold에 의한 test error 추정치는

![image](https://github.com/user-attachments/assets/624bc246-7f41-41e4-9ab3-620f84551ef3)

- k 는 보통 5, 10 을 사용한다.

  ![image](https://github.com/user-attachments/assets/312d499d-c52b-4495-8f9a-e8bdf3d2ef57)

## 장단점

`-` 장점

- LOOCV에 비해 계산량이 현저히 감소한다.
  - 쪼갠 만큼만 계산하면 되기 때문이다.
  - k가 클 때 훈련데이터가 커지므로 과소추정을 막는다.
  
- LOOCV에 비해 test error의 추정이 오히려 정확한 경우가 종종 발생한다. ( 훈련자료의 Overlap 경감효과 )
  - LOOCV는 n번째를 맞추기 위해 n-1개의 데이터를 사용하는데 훈련오차와 평가데이터 사이의 차이가 많이 안날 수 있다.
  - LOOCV는 데이터가 커지면 훈련데이터와 평가데이터의 예측오차의 차이가 비슷해져서 추정이 안좋아질 수 있다.
  - 훈련할 때 데이터가 중복되므로 경감효과가 발생하는데 이게 문제가 될때도 있다.

`-` 단점

- k개의 집합으로 분할 시 randomeness 가 발생하여 test error 추정시 변동성이 발생함
- 하지만 validation set approach 보다는 훨씬 안정적이다.
  - test error가 다를 수 있으므로 평균, 분산을 같이 보는 것이 좋다.
  - 데이터마다 적절한 k가 다르다.

# test error의 추정 (LOOCV vs K-fold CV)
![image](https://github.com/user-attachments/assets/2c477ae0-de05-477d-bd68-d5e695abc839)

- 두 그래프 모두 2에서 확 꺾이므로 2를 선택하는 것이 좋다.
- k-fold cv는 선이 여러 개인데, 선들의 평균으로 봐야 한다.

# 분류문제에서의 CV
-  교차타당검증법은 자료를 어떻게 분할할 것인가에 대한 문제이므로 평가 측도와는 큰 관련이 없다.
-  평가자료에서의 오분류율, 민감도, 특이도, AUC 등을 분류기에 대한 지표로 사용할 수 있다.

![image](https://github.com/user-attachments/assets/385e870b-b9b2-4f96-b039-eb260a5bbd75)

# test error의 minimizer



