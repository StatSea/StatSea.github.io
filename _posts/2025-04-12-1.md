---
layout: single
title: "[ML] 기계학습 Chap 1"
categories: [ML]
tags: [ML]
---
기계학습 Chap 1 정리

---
# 통계학 vs 기계학습

`-` 통계학 : 모형과 데이터로부터 모집단, 모수에 대한 추론, 해석에 초점을 맞춤

`-` 기계학습 : 모형과 데이터로부터 새로운 현상에 대한 예측에 초점을 맞춤

- 지향점은 차이가 있지만 사용하는 도구에 공통점이 많고 데이터를 다룬다는 점에서 큰 유사성을 가진다.

# 통계적 학습의 역사
`-` 기계학습의 정의 : 경험을 통해 자동으로 개선하는 컴퓨터 알고리즘의 연구 
- 19세기 초 : 최소제곱법에 근거한 선형회귀모형 등장
- 1936년 : 판별분석
- 1940년 : 로지스틱 모형
- 1970년 초 : 선형모형 + 로지스틱 모형들 인 일반화선형모형 개념 소개
- 1980년 : 계산성능의 상향으로 비선형모형 적용 가능해짐
- 1980 중반 : 나무모형에 근거한 회귀/분류 방법들 제안 , 선형 회귀 모형의 한계를 극복한 일반화가법모형 소개

`-` 통계학 = 계산학 + 컴퓨터 공학

`-` 기계학습 : 다층퍼셉트론, 서포트벡터기계 , 심층신경망, 강화학습의 발전과 궤를 같이함

# 기계학습의 영역
- 비지도학습, 지도학습, 강화학습
---

# 회귀분석 예제
`-` 광고데이터로 보는 예제
- 그래프를 볼때는 선형성, 등분산성, 독립성, 정규성을 따져봐야 한다.
---
- 회귀분석 : $$\hat{y} = X \hat{\beta}$$ 로 $$\hat{y}$$ 을 추정하는 것
- 기계학습 : y 자체를 추정하는 것

- 일반적으로 p개의 예측변수와 반응변수 y가 다음과 같은 관계를 가진다고 가정했을 때

$$y = f(x) + \varepsilon$$


f를 데이터에 근거하여 추정하여 y를 예측하는 방법론들을 일컬어 통계적 학습이라 한다.

- $$\varepsilon$$ : 평균이 0이고 분산이 $$\sigma^2$$
- x는 고정이 가능하지만 y 는 $$\varepsilon$$ 로 인해 불가능하다.
-  따라서 x가 고정되었을때의 y의 평균 = f(x)이다.

---
## 왜 f를 추정하는가?
- 예측 : $$\hat{y} = \hat{f}(x)$$
- 예측에만 목적이 있을 경우 $$\hat{f}(x)$$의 정확한 함수 형태를 아는 것은 중요하지 않다.
- Y에 대한 예측은 평균값이 최선이 된다.
- 예측변수로부터 반응변수의 평균을 예측하는 문제 = 평균으로 예측하는게 최선

$$
\arg\min_{c(x)} \mathbb{E}[(T - c(x))^2] = \mathbb{E}[y \mid x] = f(x)
$$

- c(x)는 x를 동원해서 y를 예측하기 위한 함수이다.
![image](https://github.com/user-attachments/assets/4658453d-0086-403a-a87e-9b296e78e37e)

따라서 통계적 학습의 궁걱적인 목표는 낮은 예측 오차 $$\mathbb{E}[(y - \hat{y})^2]$$ 이므로 f(x)를 추정하는 예측 문제로 귀결된다.

## 예측 정확도 (예측 오차)의 분해
`-` Reducible error : 피할 수 있는 값 , 줄일 수 있는 오차

`-` irreducible error : 피할수 없는 값 , 하한값 , f의 형태에 따라 변하는 값

- 예시
  
$$
\mathbb{E}[(f(x) - \hat{f}(x))^2] + \text{Var}(\varepsilon)
$$

- $$\mathbb{E}[(f(x) - \hat{f}(x))^2]$$ = Reducible error
- $$\text{Var}(\varepsilon)$$ = irreducible error

---

## 어떻게 f를 추정할 수 있는가?
`-` 모수적 방법

- f의 형태를 구체적으로 가정한 후 데이터로부터 모형의 학습을 통해 f를 추정한다.
- 선형회귀 모형

`-` 비모수적 방법

- f의 형태에 구체적인 가정 없이 데이터로부터 모형의 학습을 통해 f를 추정
- 함수형태에 대한 가정은 완전히 피할 수 없지만 모형의 유연성(복잡성) 증가로 데이터 적합성이 좋아짐
  - 복잡도 측정 : 미분
  - 변수의 개수 증가, 비선형, 함수의 형태 = 유연성(복잡성)증가

---
# 예측정확성 vs 모델 해석 가능성
- 위 개념 사이에 적절한 타협이 필요하다.
- 정확도가 높은 모형들의 해석가능성은 낮은 편이다.
- 변수가 많으면 해석가능성은 낮아지지만 예측정확성은 높아진다.
- 또한 복잡도가 무조건 높다고 좋은 것도 아니다.

 ![image](https://github.com/user-attachments/assets/3c9aa852-d84a-49d4-961e-7568e3a2c514)
---

# 지도학습 vs 비지도학습
- label / response의 존재 여부에 따라 구분한다.

`-` 지도학습 : 회귀분석, 분류분석 , 반응변수 존재

`-` 비지도학습 : 군집분석, 연관분석 , 반응변수 존재 x

- 지도학습은 0,1 등등 반응변수 맞추는 것, 군집분석은 기계와 사람 판별과 같은 것

---

# 회귀분석 vs 분류분석
- 반응변수의 형태에 따라 구분
`-` 회귀분석 : 반응변수가 양적변수 (연속형) 인 경우

  - 회귀분석 : 특정한 변수의 평균을 다른 변수들로 예측하는 것
  
`-` 분류분석 : 반응변수가 질적변수 (범주형)인 경우

  - 로지스틱 회귀분석
