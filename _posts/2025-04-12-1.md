---
layout: single
title: "[ML] 기계학습 Chap 1,2 "
categories: [ML]
tags: [ML]
---
기계학습 Chap 1,2 정리

---
# 통계학 vs 기계학습

`-` 통계학 : 모형과 데이터로부터 모집단, 모수에 대한 추론, 해석에 초점을 맞춤

`-` 기계학습 : 모형과 데이터로부터 새로운 현상에 대한 예측에 초점을 맞춤

- 지향점은 차이가 있지만 사용하는 도구에 공통점이 많고 데이터를 다룬다는 점에서 큰 유사성을 가진다.

# 통계적 학습의 역사
`-` 기계학습의 정의 : 경험을 통해 자동으로 개선하는 컴퓨터 알고리즘의 연구 
- 19세기 초 : 최소제곱법에 근거한 선형회귀모형 등장
- 1936년 : 판별분석
- 1940년 : 로지스틱 모형
- 1970년 초 : 선형모형 + 로지스틱 모형들 인 일반화선형모형 개념 소개
- 1980년 : 계산성능의 상향으로 비선형모형 적용 가능해짐
- 1980 중반 : 나무모형에 근거한 회귀/분류 방법들 제안 , 선형 회귀 모형의 한계를 극복한 일반화가법모형 소개

`-` 통계학 = 계산학 + 컴퓨터 공학

`-` 기계학습 : 다층퍼셉트론, 서포트벡터기계 , 심층신경망, 강화학습의 발전과 궤를 같이함

# 기계학습의 영역
- 비지도학습, 지도학습, 강화학습
---

# 회귀분석 예제
`-` 광고데이터로 보는 예제
- 그래프를 볼때는 선형성, 등분산성, 독립성, 정규성을 따져봐야 한다.
---
- 회귀분석 : $$\hat{y} = X \hat{\beta}$$ 로 $$\hat{y}$$ 을 추정하는 것
- 기계학습 : y 자체를 추정하는 것

- 일반적으로 p개의 예측변수와 반응변수 y가 다음과 같은 관계를 가진다고 가정했을 때

$$y = f(x) + \varepsilon$$


f를 데이터에 근거하여 추정하여 y를 예측하는 방법론들을 일컬어 통계적 학습이라 한다.

- $$\varepsilon$$ : 평균이 0이고 분산이 $$\sigma^2$$
- x는 고정이 가능하지만 y 는 $$\varepsilon$$ 로 인해 불가능하다.
-  따라서 x가 고정되었을때의 y의 평균 = f(x)이다.

---
## 왜 f를 추정하는가?
- 예측 : $$\hat{y} = \hat{f}(x)$$
- 예측에만 목적이 있을 경우 $$\hat{f}(x)$$의 정확한 함수 형태를 아는 것은 중요하지 않다.
- Y에 대한 예측은 평균값이 최선이 된다.
- 예측변수로부터 반응변수의 평균을 예측하는 문제 = 평균으로 예측하는게 최선

$$
\arg\min_{c(x)} \mathbb{E}[(T - c(x))^2] = \mathbb{E}[y \mid x] = f(x)
$$

- c(x)는 x를 동원해서 y를 예측하기 위한 함수이다.
![image](https://github.com/user-attachments/assets/4658453d-0086-403a-a87e-9b296e78e37e)

따라서 통계적 학습의 궁걱적인 목표는 낮은 예측 오차 $$\mathbb{E}[(y - \hat{y})^2]$$ 이므로 f(x)를 추정하는 예측 문제로 귀결된다.

## 예측 정확도 (예측 오차)의 분해
`-` Reducible error : 피할 수 있는 값 , 줄일 수 있는 오차

`-` irreducible error : 피할수 없는 값 , 하한값 , f의 형태에 따라 변하는 값

- 예시
  
$$
\mathbb{E}[(f(x) - \hat{f}(x))^2] + \text{Var}(\varepsilon)
$$

- $$\mathbb{E}[(f(x) - \hat{f}(x))^2]$$ = Reducible error
- $$\text{Var}(\varepsilon)$$ = irreducible error

---

## 어떻게 f를 추정할 수 있는가?
`-` 모수적 방법

- f의 형태를 구체적으로 가정한 후 데이터로부터 모형의 학습을 통해 f를 추정한다.
- 선형회귀 모형

`-` 비모수적 방법

- f의 형태에 구체적인 가정 없이 데이터로부터 모형의 학습을 통해 f를 추정
- 함수형태에 대한 가정은 완전히 피할 수 없지만 모형의 유연성(복잡성) 증가로 데이터 적합성이 좋아짐
  - 복잡도 측정 : 미분
  - 변수의 개수 증가, 비선형, 함수의 형태 = 유연성(복잡성)증가

---
# 예측정확성 vs 모델 해석 가능성
- 위 개념 사이에 적절한 타협이 필요하다.
- 정확도가 높은 모형들의 해석가능성은 낮은 편이다.
- 변수가 많으면 해석가능성은 낮아지지만 예측정확성은 높아진다.
- 또한 복잡도가 무조건 높다고 좋은 것도 아니다.

 ![image](https://github.com/user-attachments/assets/3c9aa852-d84a-49d4-961e-7568e3a2c514)
---

# 지도학습 vs 비지도학습
- label / response의 존재 여부에 따라 구분한다.

`-` 지도학습 : 회귀분석, 분류분석 , 반응변수 존재

`-` 비지도학습 : 군집분석, 연관분석 , 반응변수 존재 x

- 지도학습은 0,1 등등 반응변수 맞추는 것, 군집분석은 기계와 사람 판별과 같은 것

---

# 회귀분석 vs 분류분석
- 반응변수의 형태에 따라 구분
`-` 회귀분석 : 반응변수가 양적변수 (연속형) 인 경우

  - 회귀분석 : 특정한 변수의 평균을 다른 변수들로 예측하는 것
  
`-` 분류분석 : 반응변수가 질적변수 (범주형)인 경우

  - 로지스틱 회귀분석

---
# 모형 평가
- 여러 학습법이 소개되는 이유는 모든 데이터에서 항상 가장 우수한 모형은 존재하지 않기 때문이다.
- 다양한 학습법의 평가 및 비교를 위한 측도가 필요하다.
- 목적에 따라 측도는 달라질 수 있다.
- 모형의 수준
  - 대범주 : 회귀모형, 분류모형 등
  - 소범주 : 단순선형회귀, 같은 구조를 가지는 딥 네트워크 등
  - 세부범주 : 같은 소범주모형 안에서 계수가 다른 것들

---
# 평가 측도 : 회귀모형
`-` 평균 제곱 오차

$$
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$


![image](https://github.com/user-attachments/assets/ebafdf67-a265-4d8b-858e-f8514da3840e)

- 훈련데이터는 추정에 사용되며 평가 데이터는 예측의 정확도를 위해서 훈련데이터와 구별되는 데이터이다.
- test의 MSE를 보고 예측의 정확도를 판별할 수 있다.
- 훈련자료의 MSE를 가능하면 최소화시키는 학습법을 찾는 것이 항상 좋은가?
  - 훈련은 훈련자료의 MSE를 줄이는 것을 목표로 하면서도 평가 데이터에서도 높은 성능을 보여야 한다.
  - cov를 작게 만들기 등등..

---

# 과적합 문제
- 훈련데이터에 너무 집중한 경우
- 훈련 MSE가 과도하게 작아지는 모형 적합 시 , 평가 MSE가 증가하는 현상이 발생하기도 한다.
  - 모형이 훈련 자료의 적합에 지나치게 집중되어 예측의 변동성을 증가시키기 때문


![image](https://github.com/user-attachments/assets/5b32a245-51c3-4de0-92e7-536b6ee41f35)


## 예시

![image](https://github.com/user-attachments/assets/99992316-fd73-4998-aab5-b8aa3ed391e1)

![image](https://github.com/user-attachments/assets/b8167194-973e-45e9-a0db-c87524dc4d1b)

- var을 줄이는 법 : 샘플 사이즈 늘리기
- Boosting : 샘플 사이즈 up , 모형 컨트롤
- 딥네트워크 : 복잡도 up


## Bias - Variandce Trade off
- 평가 MSE의 기대값의 분해

![image](https://github.com/user-attachments/assets/47d570f3-7f95-4392-b689-9e0f405f4c25)

  -모형의 분산 : 훈련자료의 변화에 f가 얼마나 민감하게 변화하는가? - 오버 피팅
  -모형의 편의 : 실제자료를 모형으로 얼마나 가깝게 근사할수 있는가? - 언더 피팅
  - 주어진 데이터의 크기가 같을 때 더 복잡한 모형은 더 큰 분산을 가지고 , 더 단순한 모형일수록 큰 편의를 가진다.

--

# 평가 측도 : 분류모형
- 오류율
  
$$
\text{Error Rate} = \frac{\text{Number of Incorrect Predictions}}{\text{Total Number of Predictions}} = \frac{1}{n} \sum_{i=1}^{n} \mathbb{I}(\hat{y}_i \ne y_i)
$$

- 범주형 분류에서는 MSE를 사용하지 않고 zero1 loss를 사용한다.
  - 맞추면 손실 x
  - 못맞추면 손실 o
- 평가자료에서의 오류율을 최소화하는 것이 목표
- 일반적으로 다음을 최대화 하는 방식으로 분류하는 것이 평가 자료의 오류율을 최소화 시킨다.

$$
\Pr(y = j \mid x = x_0)
$$

--
# 베이즈 분류기

$$
\Pr(y = j \mid x = x_0) > 0.5 
$$

- 위의 경우를 만족하는 경우 1로 분류함
- 베이즈 분류기를 실제로 얻는 것은 불가능하다. 모집단의 조건부 분포를 모르는 것이 일반적이기 때문이다.
- 많은 분류방법들이 위 조건부 확률의 추정에 기반하고 있다.
- 최대 확률의 값을 정확히 몰라도 예측이 가능해서 확률의 적합성 문제가 발생한다.
   
