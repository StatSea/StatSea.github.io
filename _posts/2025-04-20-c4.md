---
layout: single
title: "[ML] 기계학습 Chap 5 코드 정리"
categories: [ML]
tags: [ML]
mathjax: true
---
기계학습 Chap 5 코드 정리

---

# 1. 기본 세팅
```python
!pip install ISLP
import numpy as np
import statsmodels.api as sm
from ISLP import load_data
from ISLP.models import (ModelSpec as MS, summarize, poly)

from sklearn.model_selection import train_test_split
import numpy as np
import statsmodels.api as sm
from ISLP import load_data
from ISLP.models import (ModelSpec as MS, summarize, poly)

from sklearn.model_selection import train_test_split

from functools import partial
from sklearn.model_selection import (cross_validate , KFold , ShuffleSplit)
from sklearn.base import clone
from ISLP.models import sklearn_sm
```
# 2. Validation and CV
- Auto data 로딩 및 데이터 쪼개기
- Validation 오차 확인

```python
# 자동차 데이터
# 데이터를 쪼갠다. test = 100 으로, 나머지는 훈련데이터로

Auto = load_data('Auto')
Auto_train, Auto_valid = train_test_split(Auto, test_size=100, random_state=0)

hp_mm = MS(['horsepower'])
X_train = hp_mm.fit_transform(Auto_train)
y_train = Auto_train['mpg']
model = sm.OLS(y_train, X_train)
results = model.fit()
print(results.summary())

X_valid = hp_mm.transform(Auto_valid)
y_valid = Auto_valid['mpg']
valid_pred = results.predict(X_valid)
train_pred = results.predict(X_train)

print(np.mean((y_train - train_pred)**2))
print(np.mean((y_valid - valid_pred)**2))


# 292개로 훈련을 했고 100개로 평가를 했다.
# 각각의 계수들도 유의하고 r스퀘어도 잘 나왔음
# 훈련 예측오차 24.228
# 테스트 예측오차 23.201
# 보통 테스트가 더 높은데 왜 이렇게 결과가 나왔을까? = 테스트 데이터 개수 때문, test=200 , random=100으로 하면 테스트가 더 크게 나옴
```
![image](https://github.com/user-attachments/assets/43bccea9-0a4a-43e1-8d6b-4c6a115fabe9)
- r스퀘어도 0.599로 잘 나옴
- 회귀모형이 유의함
- 회귀계수들도 유의함

```python
# 훈련과 검증(평가) 오차를 확인하는 함수 생성
# -------------------------------------
def evalMSE(terms, response , train , test):
    mm = MS(terms)
    X_train = mm.fit_transform(train)
    y_train = train[response]
    X_test = mm.transform(test)
    y_test = test[response]
    results = sm.OLS(y_train, X_train).fit()
    test_pred = results.predict(X_test)
    return np.mean((y_test - test_pred)**2)
```

- 다항모형의 차수를 바꾸면서 검증 오차를 확인

```python
# vailidation appoarach

MSE = np.zeros(3)
for idx, degree in enumerate(range(1, 4)):
    MSE[idx] = evalMSE([poly('horsepower', degree)], 'mpg', Auto_train, Auto_valid)
MSE

# poly수준을 바꿈 , 1차 2차 3차
# 차수가 올라간다면 -> 예시로 3차면 절편 1차 2차 3차를 씀
# 예) 3차면 → [1, horsepower, horsepower², horsepower³]
# 1->2차일때 오차가 많이 줄어들음
```
![image](https://github.com/user-attachments/assets/d3cdd4fc-3db8-44de-afe1-5c8df64c08bc)

## 교차검증 오차
```python
hp_model = sklearn_sm(sm.OLS, MS(['horsepower']))
X, Y = Auto.drop(columns=['mpg']), Auto['mpg']

# x랑 y를 알아서 쪼갬, fold를 데이터의 사이즈만큼 씀 loocv
# cv = Auto,shape[0] === loocv
cv_results = cross_validate(hp_model, X, Y, cv=Auto.shape[0])
# mean 으로 계산할 수 밖에 없음
# 포인트 하나로만 하는게 아니기 때문에
cv_err = np.mean(cv_results['test_score'])
cv_err
```
![image](https://github.com/user-attachments/assets/9b370037-19d6-4aea-9cc7-b3d8d67a3859)

- 다항식의 차수를 키웠을 때의 교차검증오차를 확인
```python
cv_error = np.zeros(5)
H = np.array(Auto['horsepower'])
M = sklearn_sm(sm.OLS)

for i, d in enumerate(range(1,6)):
  X = np.power.outer(H, np.arange(d+1))
  M_CV = cross_validate(M, X, Y, cv=Auto.shape[0])
  cv_error[i] = np.mean(M_CV['test_score'])

cv_error

# 차수를 1에서 5까지
# 근데 1에서 2차를 갈때 뚝 떨어짐
# 2차를 사용하는게 맞는 것으로 보임
```
![image](https://github.com/user-attachments/assets/b00275dd-dbc9-4db5-ab46-c5d1cd4e4110)

- 40 fold CV를 통해서 차수에 대한 예측 오차를 확인함

```python
cv_error = np.zeros(5)
# 40개로 쪼개는 CV
cv = KFold(n_splits=10, shuffle=True, random_state=0)
print(cv)

# use same splits for each degree for i, d in enumerate(range(1,6)):

for i, d in enumerate(range(1,6)):
    X = np.power.outer(H, np.arange(d+1))
    M_CV = cross_validate(M, X, Y, cv=cv)
    cv_error[i] = np.mean(M_CV['test_score'])
cv_error
print(cv_error)

# 1차에서 값이 크고 2차에서 값이 떨어짐
# 루프 안에서 d값에 따라 x값이 바뀌어야 함
```
![image](https://github.com/user-attachments/assets/0ce60310-95c4-4a6b-b3d5-42c88d5895c8)

- 두개로 쪼개서 validation error 확인
```python
# validation appoaroch

validation = ShuffleSplit(n_splits=1, test_size=196, random_state=0)
results = cross_validate(hp_model,
Auto.drop(['mpg'], axis=1), Auto['mpg'], cv =validation)
print(results)
```

![image](https://github.com/user-attachments/assets/e40f1fb3-75d2-4831-9d5e-80adbce1e1d3)

# 2. Boostrap
![image](https://github.com/user-attachments/assets/69a5c27b-6a59-42ab-bec2-8a51d2c2ff51)

```python
# 주어진 데이터의 인덱싱을 통해서 공분산을 얻고 해를 구함
# -------------------------------------------------------
Portfolio = load_data('Portfolio')
def alpha_func(D, idx):
    cov_ = np.cov(D[['X','Y']].loc[idx], rowvar=False)
    return ((cov_[1,1] - cov_[0,1]) / (cov_[0,0]+cov_[1,1]-2*cov_[0,1]))

# 위 함수를 구동
# --------------
rng = np.random.default_rng()
idx = rng.choice(100, 100, replace=True)
idx = range(Portfolio.shape[0])
alpha_func(Portfolio, idx)
# index를 랜덤하게 정해서 결과를 확인

# 알파의 추정량인데 신뢰구간을 구해야 알파가 얼마나 왔다갔다 하는지 알아볼 수 있음 => 붓스트랩 기법 적용
```

- 붓스트랩 기법의 적용(알파)
  - 알파에 대한 계산을 여러 개의 복원추출 샘플로 구한다.
  - 여기에 나온 여러 개의 알파로 추정량 알파의 표준편차를 추정한다.

```python
def boot_SE(func, D, n=None, B=1000, seed=0):
    rng = np.random.default_rng(seed)
    first_ , second_ = 0, 0
    n = n or D.shape[0]
    for _ in range(B):
        idx = rng.choice(D.index, n, replace=True)
        value = func(D, idx)
        first_ += value
        second_ += value**2
    return np.sqrt(second_ / B - (first_ / B)**2) # 표준편차 계산

alpha_SE = boot_SE(alpha_func, Portfolio ,B=1000, seed=1)
alpha_SE

# 알파를 여러개 만들어서 추정량의 표준편차를 구했음
```

- 붓스트랩 기법의 적용 (OLS)
  - 복원추출로 여러 개의 샘플을 만들어 회귀계수들을 확인
 
```python
def boot_OLS(model_matrix, response, D, idx):
   D_ = D.iloc[idx]     #D.iloc #
   Y_ = D_[response]
   X_ = clone(model_matrix).fit_transform(D_)
   return sm.OLS(Y_, X_).fit().params

hp_func = partial(boot_OLS, MS(['horsepower']), 'mpg')
# 함수를 구동할 때 모든 인자가 아니라 필요 인지만 받을 수 있게 함
# 앞에 두 인자는 고정시키게 됨

# 회귀계수에도 사용할 수 있음

rng = np.random.default_rng(0)
kk = [hp_func(Auto, rng.choice(392, 392, replace=True)) for _ in range(10)]
print(np.array(kk))
```
![image](https://github.com/user-attachments/assets/64294f21-1c9e-4e43-8f73-8259804cf87a)

- 붓스트랩으로 얻은 표준오차와 일반 방법론으로 얻은 표준오차 비교

```python
def boot_OLS(model_matrix, response, D, idx):
   D_ = D.loc[idx]     #D.iloc #
   Y_ = D_[response]
   X_ = clone(model_matrix).fit_transform(D_)
   return sm.OLS(Y_, X_).fit().params

hp_func = partial(boot_OLS, MS(['horsepower']), 'mpg')
hp_se = boot_SE(hp_func, Auto, B=1000, seed=0)
print(hp_se)

hp_model.fit(Auto, Auto['mpg'])
model_se = summarize(hp_model.results_)['std err']
print(model_se)

# 표준 오차 (위는 붓스트랩, 밑은 그냥 구한것)
# 표준 오차는 일반적코드로도 구해짐
```

![image](https://github.com/user-attachments/assets/b64d0bb1-ccd7-41d8-aa7c-f81ab01fbd50)

```python
quad_model = MS([poly('horsepower', 2, raw=True)])
quad_func = partial(boot_OLS, quad_model, 'mpg')
print(boot_SE(quad_func, Auto, B=1000))

M = sm.OLS(Auto['mpg'], quad_model.fit_transform(Auto))
print(summarize(M.fit())['std err'])
```

- 대충 비슷하게 나온다.
